{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC478 Machine Learning - Spring 2021</font>\n",
    "\n",
    "## Instructor: Fereydoon Vafaei\n",
    "\n",
    "## <font color=\"blue\">Assignment-4: Multi-Class Classification and Regression with Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Caleb M. McLaren, CU01417* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Assignment-4, you're going to perform multi-class classification and regression using Neural Networks in Tensorflow/Keras.\n",
    "\n",
    "Pedagogically, this assignment will help you:\n",
    "- better understand how neural networks are built and applied on ML tasks - specifically multi-class classification and regression.\n",
    "- practice NN implementation using Tensorflow 2 and Keras Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Course Policy Reminder</b>\n",
    "Debugging the codes and error resolution are always the students' responsbility. This policy will be enforced in email communications and the office hours. Keep in mind that all assignments are individual graded tasks. Any collaboration with other students is strictly prohibited and is considered as cheating. Students should NOT share any answer, solution, or code with other students. Violations of these policies would be penalized according to UMBC academic integrity policy.\n",
    "\n",
    "**You must run ALL cells** and get the correct outputs for all cells and give complete answers to all questions. **Cells/codes with no output get zero!**\n",
    "\n",
    "Follow the instructions for each step very carefully.\n",
    "\n",
    "Wherever needed, you should replace `...` elipsis with your code.\n",
    "\n",
    "`...` may indicate one or more lines of missing codes. Some outputs are provided to you to use as reference and to verify that your output is correct.\n",
    "\n",
    "**Preprocessing Effect on Grade**: Preprocessing steps are so critical in each part and you should pay special attention to make sure that you do all preprocessing steps correctly. That is why the reference outputs have been provided in preprocessing steps. Even though preprocessing steps have no direct positive points themselves, they have negative impact if you make mistakes in preprocessing, and your notebook would become unqualified for grading implementation due to wrong results/outputs, and consequently you may get zero for that part of the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is importing all necessary python, sklearn and Tensorflow/Keras modules. **You definitely need to add to the imports as you work on the assignment.** When you import a new module, add it here in the same cell. All imports should be in this import cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import Cell\n",
    "    Import necessary Python/Sklearn modules as well as Tensorflow/Keras '''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be no error/output after running this cell if the installation is correct\n",
    "tf.debugging.Assert(tf.__version__ >= '2.0.0', [\"You should install Tensorflow 2.x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-I - Multi-Class Classification Using NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part-I, you're going to use tf/keras to build a NN for multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the dataset `Sensorless_drive_diagnosis.txt` from [UCI ML Repository page](https://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis#). The dataset file is in the `Data Folder`.\n",
    "\n",
    "\"Features are extracted from motor current. The motor has intact and defective components. This results in 11 different classes with different conditions.\" You're going to predict these 11 classes. Therefore, this is a multi-class classification problem.\n",
    "\n",
    "Load the text file using pandas `read_csv` considering that the separator is a space `' '`  and the file has no header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58508, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3             4         5         6   \\\n",
       "0  0.000003 -0.000005  0.000003 -0.000006  2.778900e-06 -0.000004  0.030804   \n",
       "1 -0.000003 -0.000003 -0.000016 -0.000001 -1.575300e-06  0.000017  0.032877   \n",
       "2 -0.000001  0.000009 -0.000016 -0.000005 -7.282900e-07  0.000004  0.029410   \n",
       "\n",
       "         7         8         9   ...       39      40      41      42      43  \\\n",
       "0  0.030810  0.030806 -0.033520  ... -0.59314  7.6252  6.1690 -1.4967 -1.4967   \n",
       "1  0.032880  0.032896 -0.029834  ... -0.63252  2.7784  5.3017 -1.4983 -1.4983   \n",
       "2  0.029401  0.029417 -0.030156  ... -0.62289  6.5534  6.2606 -1.4963 -1.4963   \n",
       "\n",
       "       44      45      46      47  48  \n",
       "0 -1.4967 -1.5005 -1.5005 -1.5005   1  \n",
       "1 -1.4982 -1.4985 -1.4985 -1.4985   1  \n",
       "2 -1.4963 -1.4975 -1.4975 -1.4976   1  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = list(range(0,49))\n",
    "data1 = pd.read_csv(r\"Sensorless_drive_diagnosis.txt\", ' ', header=0, names=col_list)\n",
    "print(data1.shape)\n",
    "data1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the file has no header, column names are integers from 0 to 48, and the last column is the target class. Name the columns from `col1` to `col49` as specified in the provided output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16', 'col17', 'col18', 'col19', 'col20', 'col21', 'col22', 'col23', 'col24', 'col25', 'col26', 'col27', 'col28', 'col29', 'col30', 'col31', 'col32', 'col33', 'col34', 'col35', 'col36', 'col37', 'col38', 'col39', 'col40', 'col41', 'col42', 'col43', 'col44', 'col45', 'col46', 'col47', 'col48', 'col49']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "      <th>col49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-6.056100e-06</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-1.208400e-06</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-4.811100e-06</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-6.490100e-06</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.584900e-07</td>\n",
       "      <td>5.214300e-08</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>6.453700e-07</td>\n",
       "      <td>-2.304100e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>-0.032789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.61124</td>\n",
       "      <td>5.8337</td>\n",
       "      <td>18.6970</td>\n",
       "      <td>-1.4956</td>\n",
       "      <td>-1.4956</td>\n",
       "      <td>-1.4956</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           col1          col2      col3          col4          col5      col6  \\\n",
       "0  2.913200e-06 -5.247700e-06  0.000003 -6.056100e-06  2.778900e-06 -0.000004   \n",
       "1 -2.951700e-06 -3.184000e-06 -0.000016 -1.208400e-06 -1.575300e-06  0.000017   \n",
       "2 -1.322600e-06  8.820100e-06 -0.000016 -4.811100e-06 -7.282900e-07  0.000004   \n",
       "3 -6.836600e-08  5.666300e-07 -0.000026 -6.490100e-06 -7.940600e-07  0.000013   \n",
       "4 -9.584900e-07  5.214300e-08 -0.000047  6.453700e-07 -2.304100e-06  0.000055   \n",
       "\n",
       "       col7      col8      col9     col10  ...    col40   col41    col42  \\\n",
       "0  0.030804  0.030810  0.030806 -0.033520  ... -0.59314  7.6252   6.1690   \n",
       "1  0.032877  0.032880  0.032896 -0.029834  ... -0.63252  2.7784   5.3017   \n",
       "2  0.029410  0.029401  0.029417 -0.030156  ... -0.62289  6.5534   6.2606   \n",
       "3  0.030119  0.030119  0.030145 -0.031393  ... -0.63010  4.5155   9.5231   \n",
       "4  0.031154  0.031154  0.031201 -0.032789  ... -0.61124  5.8337  18.6970   \n",
       "\n",
       "    col43   col44   col45   col46   col47   col48  col49  \n",
       "0 -1.4967 -1.4967 -1.4967 -1.5005 -1.5005 -1.5005      1  \n",
       "1 -1.4983 -1.4983 -1.4982 -1.4985 -1.4985 -1.4985      1  \n",
       "2 -1.4963 -1.4963 -1.4963 -1.4975 -1.4975 -1.4976      1  \n",
       "3 -1.4958 -1.4958 -1.4958 -1.4959 -1.4959 -1.4959      1  \n",
       "4 -1.4956 -1.4956 -1.4956 -1.4973 -1.4972 -1.4973      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = list(range(0,49))\n",
    "for i in col_list:\n",
    "    col_list[i] = \"col\"+ str(int(col_list[i]) + 1)\n",
    "    \n",
    "col_list[48] = (\"col49\")\n",
    "print(col_list)\n",
    "\n",
    "data1.columns = col_list\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename the last column, i.e. the target column, from `col49` to `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-6.056100e-06</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-1.208400e-06</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-4.811100e-06</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-6.490100e-06</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.584900e-07</td>\n",
       "      <td>5.214300e-08</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>6.453700e-07</td>\n",
       "      <td>-2.304100e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>-0.032789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.61124</td>\n",
       "      <td>5.8337</td>\n",
       "      <td>18.6970</td>\n",
       "      <td>-1.4956</td>\n",
       "      <td>-1.4956</td>\n",
       "      <td>-1.4956</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>-1.4973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           col1          col2      col3          col4          col5      col6  \\\n",
       "0  2.913200e-06 -5.247700e-06  0.000003 -6.056100e-06  2.778900e-06 -0.000004   \n",
       "1 -2.951700e-06 -3.184000e-06 -0.000016 -1.208400e-06 -1.575300e-06  0.000017   \n",
       "2 -1.322600e-06  8.820100e-06 -0.000016 -4.811100e-06 -7.282900e-07  0.000004   \n",
       "3 -6.836600e-08  5.666300e-07 -0.000026 -6.490100e-06 -7.940600e-07  0.000013   \n",
       "4 -9.584900e-07  5.214300e-08 -0.000047  6.453700e-07 -2.304100e-06  0.000055   \n",
       "\n",
       "       col7      col8      col9     col10  ...    col40   col41    col42  \\\n",
       "0  0.030804  0.030810  0.030806 -0.033520  ... -0.59314  7.6252   6.1690   \n",
       "1  0.032877  0.032880  0.032896 -0.029834  ... -0.63252  2.7784   5.3017   \n",
       "2  0.029410  0.029401  0.029417 -0.030156  ... -0.62289  6.5534   6.2606   \n",
       "3  0.030119  0.030119  0.030145 -0.031393  ... -0.63010  4.5155   9.5231   \n",
       "4  0.031154  0.031154  0.031201 -0.032789  ... -0.61124  5.8337  18.6970   \n",
       "\n",
       "    col43   col44   col45   col46   col47   col48  class  \n",
       "0 -1.4967 -1.4967 -1.4967 -1.5005 -1.5005 -1.5005      1  \n",
       "1 -1.4983 -1.4983 -1.4982 -1.4985 -1.4985 -1.4985      1  \n",
       "2 -1.4963 -1.4963 -1.4963 -1.4975 -1.4975 -1.4976      1  \n",
       "3 -1.4958 -1.4958 -1.4958 -1.4959 -1.4959 -1.4959      1  \n",
       "4 -1.4956 -1.4956 -1.4956 -1.4973 -1.4972 -1.4973      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.rename(columns={\"col49\":\"class\"}, inplace=True)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are 11 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The dataset is balanced with respect to 11 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1     5318\n",
       "2     5319\n",
       "3     5319\n",
       "4     5319\n",
       "5     5319\n",
       "6     5319\n",
       "7     5319\n",
       "8     5319\n",
       "9     5319\n",
       "10    5319\n",
       "11    5319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.groupby('class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1     0\n",
       "col2     0\n",
       "col3     0\n",
       "col4     0\n",
       "col5     0\n",
       "col6     0\n",
       "col7     0\n",
       "col8     0\n",
       "col9     0\n",
       "col10    0\n",
       "col11    0\n",
       "col12    0\n",
       "col13    0\n",
       "col14    0\n",
       "col15    0\n",
       "col16    0\n",
       "col17    0\n",
       "col18    0\n",
       "col19    0\n",
       "col20    0\n",
       "col21    0\n",
       "col22    0\n",
       "col23    0\n",
       "col24    0\n",
       "col25    0\n",
       "col26    0\n",
       "col27    0\n",
       "col28    0\n",
       "col29    0\n",
       "col30    0\n",
       "col31    0\n",
       "col32    0\n",
       "col33    0\n",
       "col34    0\n",
       "col35    0\n",
       "col36    0\n",
       "col37    0\n",
       "col38    0\n",
       "col39    0\n",
       "col40    0\n",
       "col41    0\n",
       "col42    0\n",
       "col43    0\n",
       "col44    0\n",
       "col45    0\n",
       "col46    0\n",
       "col47    0\n",
       "col48    0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NAs, and drop NAs if there is any\n",
    "data1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate features from the target column, so `X` should contain all feature columns `col1` to `col48` and of course should NOT include `class`. `y` should contain `class` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58508, 48)\n",
      "(58508,)\n"
     ]
    }
   ],
   "source": [
    "temp_list = col_list[:48]\n",
    "#print(temp_list)\n",
    "\n",
    "X = data1[temp_list]\n",
    "y = data1[\"class\"]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>...</th>\n",
       "      <th>col39</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58508.000000</td>\n",
       "      <td>5.850800e+04</td>\n",
       "      <td>5.850800e+04</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>5.850800e+04</td>\n",
       "      <td>5.850800e+04</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.439531e-06</td>\n",
       "      <td>1.412234e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>1.351287e-06</td>\n",
       "      <td>-2.650900e-07</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>-0.011897</td>\n",
       "      <td>...</td>\n",
       "      <td>8.406806</td>\n",
       "      <td>-0.397753</td>\n",
       "      <td>7.293855</td>\n",
       "      <td>8.273775</td>\n",
       "      <td>-1.500887</td>\n",
       "      <td>-1.500912</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.497771</td>\n",
       "      <td>-1.497794</td>\n",
       "      <td>-1.497686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>5.555475e-05</td>\n",
       "      <td>2.353029e-04</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>5.660992e-05</td>\n",
       "      <td>2.261926e-04</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.036466</td>\n",
       "      <td>0.036470</td>\n",
       "      <td>0.066483</td>\n",
       "      <td>...</td>\n",
       "      <td>6.897353</td>\n",
       "      <td>25.018942</td>\n",
       "      <td>12.451875</td>\n",
       "      <td>6.566008</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.013721</td>\n",
       "      <td>-5.414400e-03</td>\n",
       "      <td>-1.358000e-02</td>\n",
       "      <td>-0.012787</td>\n",
       "      <td>-8.355900e-03</td>\n",
       "      <td>-9.741300e-03</td>\n",
       "      <td>-0.139890</td>\n",
       "      <td>-0.135940</td>\n",
       "      <td>-0.130860</td>\n",
       "      <td>-0.218640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>-0.596830</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>-1.525500</td>\n",
       "      <td>-1.526200</td>\n",
       "      <td>-1.523700</td>\n",
       "      <td>-1.521400</td>\n",
       "      <td>-1.523200</td>\n",
       "      <td>-1.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.444425e-05</td>\n",
       "      <td>-7.239975e-05</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-1.475325e-05</td>\n",
       "      <td>-7.379275e-05</td>\n",
       "      <td>-0.019928</td>\n",
       "      <td>-0.019952</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>-0.032141</td>\n",
       "      <td>...</td>\n",
       "      <td>4.451300</td>\n",
       "      <td>-0.715472</td>\n",
       "      <td>1.450275</td>\n",
       "      <td>4.436275</td>\n",
       "      <td>-1.503300</td>\n",
       "      <td>-1.503400</td>\n",
       "      <td>-1.503200</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>8.803500e-07</td>\n",
       "      <td>5.140150e-07</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>7.541400e-07</td>\n",
       "      <td>-1.651450e-07</td>\n",
       "      <td>0.013226</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>-0.015566</td>\n",
       "      <td>...</td>\n",
       "      <td>6.566850</td>\n",
       "      <td>-0.661710</td>\n",
       "      <td>3.301300</td>\n",
       "      <td>6.479000</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.877725e-05</td>\n",
       "      <td>7.520175e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.906225e-05</td>\n",
       "      <td>7.138675e-05</td>\n",
       "      <td>0.024769</td>\n",
       "      <td>0.024775</td>\n",
       "      <td>0.024775</td>\n",
       "      <td>0.020615</td>\n",
       "      <td>...</td>\n",
       "      <td>9.952675</td>\n",
       "      <td>-0.573980</td>\n",
       "      <td>8.288725</td>\n",
       "      <td>9.857525</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>-1.496275</td>\n",
       "      <td>-1.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.005784</td>\n",
       "      <td>4.525300e-03</td>\n",
       "      <td>5.237700e-03</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>8.245100e-04</td>\n",
       "      <td>2.753600e-03</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.069130</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.352580</td>\n",
       "      <td>...</td>\n",
       "      <td>265.330000</td>\n",
       "      <td>3670.800000</td>\n",
       "      <td>889.930000</td>\n",
       "      <td>153.150000</td>\n",
       "      <td>-1.457600</td>\n",
       "      <td>-1.456100</td>\n",
       "      <td>-1.455500</td>\n",
       "      <td>-1.337200</td>\n",
       "      <td>-1.337200</td>\n",
       "      <td>-1.337100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               col1          col2          col3          col4          col5  \\\n",
       "count  58508.000000  5.850800e+04  5.850800e+04  58508.000000  5.850800e+04   \n",
       "mean      -0.000003  1.439531e-06  1.412234e-06     -0.000001  1.351287e-06   \n",
       "std        0.000072  5.555475e-05  2.353029e-04      0.000063  5.660992e-05   \n",
       "min       -0.013721 -5.414400e-03 -1.358000e-02     -0.012787 -8.355900e-03   \n",
       "25%       -0.000007 -1.444425e-05 -7.239975e-05     -0.000005 -1.475325e-05   \n",
       "50%       -0.000003  8.803500e-07  5.140150e-07     -0.000001  7.541400e-07   \n",
       "75%        0.000002  1.877725e-05  7.520175e-05      0.000004  1.906225e-05   \n",
       "max        0.005784  4.525300e-03  5.237700e-03      0.001453  8.245100e-04   \n",
       "\n",
       "               col6          col7          col8          col9         col10  \\\n",
       "count  5.850800e+04  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean  -2.650900e-07      0.001914      0.001913      0.001911     -0.011897   \n",
       "std    2.261926e-04      0.036468      0.036466      0.036470      0.066483   \n",
       "min   -9.741300e-03     -0.139890     -0.135940     -0.130860     -0.218640   \n",
       "25%   -7.379275e-05     -0.019928     -0.019952     -0.019925     -0.032141   \n",
       "50%   -1.651450e-07      0.013226      0.013229      0.013247     -0.015566   \n",
       "75%    7.138675e-05      0.024769      0.024775      0.024775      0.020615   \n",
       "max    2.753600e-03      0.069125      0.069130      0.069131      0.352580   \n",
       "\n",
       "       ...         col39         col40         col41         col42  \\\n",
       "count  ...  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean   ...      8.406806     -0.397753      7.293855      8.273775   \n",
       "std    ...      6.897353     25.018942     12.451875      6.566008   \n",
       "min    ...      0.522180     -0.902350     -0.596830      0.320660   \n",
       "25%    ...      4.451300     -0.715472      1.450275      4.436275   \n",
       "50%    ...      6.566850     -0.661710      3.301300      6.479000   \n",
       "75%    ...      9.952675     -0.573980      8.288725      9.857525   \n",
       "max    ...    265.330000   3670.800000    889.930000    153.150000   \n",
       "\n",
       "              col43         col44         col45         col46         col47  \\\n",
       "count  58508.000000  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean      -1.500887     -1.500912     -1.500805     -1.497771     -1.497794   \n",
       "std        0.003657      0.003667      0.003632      0.003163      0.003163   \n",
       "min       -1.525500     -1.526200     -1.523700     -1.521400     -1.523200   \n",
       "25%       -1.503300     -1.503400     -1.503200     -1.499600     -1.499600   \n",
       "50%       -1.500300     -1.500300     -1.500300     -1.498100     -1.498100   \n",
       "75%       -1.498200     -1.498200     -1.498200     -1.496200     -1.496275   \n",
       "max       -1.457600     -1.456100     -1.455500     -1.337200     -1.337200   \n",
       "\n",
       "              col48  \n",
       "count  58508.000000  \n",
       "mean      -1.497686  \n",
       "std        0.003175  \n",
       "min       -1.521300  \n",
       "25%       -1.499500  \n",
       "50%       -1.498000  \n",
       "75%       -1.496200  \n",
       "max       -1.337100  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical description of the features\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Statistical description of the features reveals that they have different scales, so you need to normalize `X`.\n",
    "\n",
    "> Use [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) to normalize X to the range (0,1) which is the default range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703624</td>\n",
       "      <td>0.544197</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.897532</td>\n",
       "      <td>0.910491</td>\n",
       "      <td>0.779322</td>\n",
       "      <td>0.816659</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.808366</td>\n",
       "      <td>0.324078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.424153</td>\n",
       "      <td>0.420827</td>\n",
       "      <td>0.395894</td>\n",
       "      <td>0.113464</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.112921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703324</td>\n",
       "      <td>0.544404</td>\n",
       "      <td>0.720815</td>\n",
       "      <td>0.897872</td>\n",
       "      <td>0.910017</td>\n",
       "      <td>0.781014</td>\n",
       "      <td>0.826577</td>\n",
       "      <td>0.823231</td>\n",
       "      <td>0.818817</td>\n",
       "      <td>0.330531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019933</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>0.400589</td>\n",
       "      <td>0.398003</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.124321</td>\n",
       "      <td>0.132796</td>\n",
       "      <td>0.123779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.703407</td>\n",
       "      <td>0.545612</td>\n",
       "      <td>0.720817</td>\n",
       "      <td>0.897619</td>\n",
       "      <td>0.910109</td>\n",
       "      <td>0.779954</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.806266</td>\n",
       "      <td>0.801421</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086379</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.430044</td>\n",
       "      <td>0.426534</td>\n",
       "      <td>0.401760</td>\n",
       "      <td>0.129750</td>\n",
       "      <td>0.138172</td>\n",
       "      <td>0.128664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703472</td>\n",
       "      <td>0.544782</td>\n",
       "      <td>0.720284</td>\n",
       "      <td>0.897501</td>\n",
       "      <td>0.910102</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.813382</td>\n",
       "      <td>0.809767</td>\n",
       "      <td>0.805061</td>\n",
       "      <td>0.327802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.060214</td>\n",
       "      <td>0.437408</td>\n",
       "      <td>0.433666</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.138436</td>\n",
       "      <td>0.146774</td>\n",
       "      <td>0.137894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703426</td>\n",
       "      <td>0.544730</td>\n",
       "      <td>0.719144</td>\n",
       "      <td>0.898002</td>\n",
       "      <td>0.909937</td>\n",
       "      <td>0.784024</td>\n",
       "      <td>0.818334</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.810341</td>\n",
       "      <td>0.325358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.120241</td>\n",
       "      <td>0.440353</td>\n",
       "      <td>0.436519</td>\n",
       "      <td>0.412023</td>\n",
       "      <td>0.130836</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.130293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.703624  0.544197  0.721839  0.897532  0.910491  0.779322  0.816659   \n",
       "1  0.703324  0.544404  0.720815  0.897872  0.910017  0.781014  0.826577   \n",
       "2  0.703407  0.545612  0.720817  0.897619  0.910109  0.779954  0.809990   \n",
       "3  0.703472  0.544782  0.720284  0.897501  0.910102  0.780702  0.813382   \n",
       "4  0.703426  0.544730  0.719144  0.898002  0.909937  0.784024  0.818334   \n",
       "\n",
       "         7         8         9   ...        38        39        40        41  \\\n",
       "0  0.813137  0.808366  0.324078  ...  0.011641  0.000084  0.009233  0.038267   \n",
       "1  0.823231  0.818817  0.330531  ...  0.019933  0.000073  0.003790  0.032592   \n",
       "2  0.806266  0.801421  0.329967  ...  0.086379  0.000076  0.008029  0.038866   \n",
       "3  0.809767  0.805061  0.327802  ...  0.017129  0.000074  0.005741  0.060214   \n",
       "4  0.814814  0.810341  0.325358  ...  0.013042  0.000079  0.007221  0.120241   \n",
       "\n",
       "         42        43        44        45        46        47  \n",
       "0  0.424153  0.420827  0.395894  0.113464  0.122043  0.112921  \n",
       "1  0.400589  0.398003  0.373900  0.124321  0.132796  0.123779  \n",
       "2  0.430044  0.426534  0.401760  0.129750  0.138172  0.128664  \n",
       "3  0.437408  0.433666  0.409091  0.138436  0.146774  0.137894  \n",
       "4  0.440353  0.436519  0.412023  0.130836  0.139785  0.130293  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use MinMaxSclaer() to normalize X features within the range (0,1) with 0 as minimum and 1 as maximum\n",
    "thisScaler = MinMaxScaler()\n",
    "X = pd.DataFrame(thisScaler.fit_transform(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now the normalized `X` statistics look a lot better! No need to rename the columns to `col1` to `col48` again, we only did it for more clarity before splitting `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "      <td>58508.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.703304</td>\n",
       "      <td>0.544870</td>\n",
       "      <td>0.721736</td>\n",
       "      <td>0.897865</td>\n",
       "      <td>0.910335</td>\n",
       "      <td>0.779601</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.663886</td>\n",
       "      <td>0.361932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.052039</td>\n",
       "      <td>0.362482</td>\n",
       "      <td>0.360747</td>\n",
       "      <td>0.335709</td>\n",
       "      <td>0.128277</td>\n",
       "      <td>0.136594</td>\n",
       "      <td>0.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.174474</td>\n",
       "      <td>0.177820</td>\n",
       "      <td>0.182358</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026047</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>0.053863</td>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.053249</td>\n",
       "      <td>0.017171</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.703094</td>\n",
       "      <td>0.543272</td>\n",
       "      <td>0.717814</td>\n",
       "      <td>0.897577</td>\n",
       "      <td>0.908581</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.573938</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.554699</td>\n",
       "      <td>0.326492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014838</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>0.326951</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.300587</td>\n",
       "      <td>0.118350</td>\n",
       "      <td>0.126882</td>\n",
       "      <td>0.118350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.703339</td>\n",
       "      <td>0.544813</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.910270</td>\n",
       "      <td>0.779609</td>\n",
       "      <td>0.732560</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.720565</td>\n",
       "      <td>0.355509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.369472</td>\n",
       "      <td>0.343109</td>\n",
       "      <td>0.126493</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>0.126493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.703556</td>\n",
       "      <td>0.546614</td>\n",
       "      <td>0.725657</td>\n",
       "      <td>0.898207</td>\n",
       "      <td>0.912265</td>\n",
       "      <td>0.785335</td>\n",
       "      <td>0.787783</td>\n",
       "      <td>0.783709</td>\n",
       "      <td>0.778209</td>\n",
       "      <td>0.418850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035613</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.062402</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.399429</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.136808</td>\n",
       "      <td>0.144758</td>\n",
       "      <td>0.136265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  58508.000000  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean       0.703304      0.544870      0.721736      0.897865      0.910335   \n",
       "std        0.003677      0.005589      0.012504      0.004396      0.006166   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.703094      0.543272      0.717814      0.897577      0.908581   \n",
       "50%        0.703339      0.544813      0.721688      0.897883      0.910270   \n",
       "75%        0.703556      0.546614      0.725657      0.898207      0.912265   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  58508.000000  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean       0.779601      0.678440      0.672222      0.663886      0.361932   \n",
       "std        0.018103      0.174474      0.177820      0.182358      0.116387   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.773716      0.573938      0.565604      0.554699      0.326492   \n",
       "50%        0.779609      0.732560      0.727408      0.720565      0.355509   \n",
       "75%        0.785335      0.787783      0.783709      0.778209      0.418850   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...            38            39            40            41  \\\n",
       "count  ...  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean   ...      0.029775      0.000137      0.008861      0.052039   \n",
       "std    ...      0.026047      0.006814      0.013983      0.042963   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.014838      0.000051      0.002299      0.026929   \n",
       "50%    ...      0.022827      0.000066      0.004377      0.040296   \n",
       "75%    ...      0.035613      0.000089      0.009978      0.062402   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 42            43            44            45            46  \\\n",
       "count  58508.000000  58508.000000  58508.000000  58508.000000  58508.000000   \n",
       "mean       0.362482      0.360747      0.335709      0.128277      0.136594   \n",
       "std        0.053863      0.052318      0.053249      0.017171      0.017007   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.326951      0.325250      0.300587      0.118350      0.126882   \n",
       "50%        0.371134      0.369472      0.343109      0.126493      0.134946   \n",
       "75%        0.402062      0.399429      0.373900      0.136808      0.144758   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 47  \n",
       "count  58508.000000  \n",
       "mean       0.128200  \n",
       "std        0.017236  \n",
       "min        0.000000  \n",
       "25%        0.118350  \n",
       "50%        0.126493  \n",
       "75%        0.136265  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using pandas [`get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) method, convert `y` to one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58508, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58504</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58505</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58506</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58508 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2   3   4   5   6   7   8   9   10  11\n",
       "0       1   0   0   0   0   0   0   0   0   0   0\n",
       "1       1   0   0   0   0   0   0   0   0   0   0\n",
       "2       1   0   0   0   0   0   0   0   0   0   0\n",
       "3       1   0   0   0   0   0   0   0   0   0   0\n",
       "4       1   0   0   0   0   0   0   0   0   0   0\n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "58503   0   0   0   0   0   0   0   0   0   0   1\n",
       "58504   0   0   0   0   0   0   0   0   0   0   1\n",
       "58505   0   0   0   0   0   0   0   0   0   0   1\n",
       "58506   0   0   0   0   0   0   0   0   0   0   1\n",
       "58507   0   0   0   0   0   0   0   0   0   0   1\n",
       "\n",
       "[58508 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You need to convert `X` and `y` to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = X.values\n",
    "y = y.values\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46806, 48)\n",
      "(46806, 11)\n",
      "(11702, 48)\n",
      "(11702, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split X, y to train and test with ratio of 80/20 for train/test respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Baseline NN Model for Multi-Class Classification with 85% Validation Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can begin with a simple neural network `baseline_model` with one or two hidden layers, 5-10 neurons per hidden layer, and increase the number of neurons and hidden layers only if needed. You may also use callback and early stopping to find the optimal number of epochs, but it's possible to obtain **the minimum required `val_accuracy` for the baseline model (0.85)** with 20 epochs and a couple of hidden layers only.\n",
    "\n",
    "> <font color='red'>**val_accuracy Requirement**</font>: The minimum required `val_accuracy` of the `baseline_model` after the last epoch of training is 0.85.\n",
    "\n",
    "> **Hints**:\n",
    "\n",
    "> - `input_dim` of the first layer should match with the number of features in `X`.\n",
    "\n",
    "> - You may use ReLU for all hidden layers, but you may also try other activation functions for the hidden layers.\n",
    "\n",
    "> - **The most common mistake** is setting wrong activation function and number of neurons in the output layer; recall that the output layer specifications are determined by the type of ML task i.e. Multi-class Classification.\n",
    "\n",
    "> - The loss function in `compile` should match with the one-hot encoded labels in `y` (check tf-notebook instructions and the links to tf documentations).\n",
    "\n",
    "> - During training, you should see a clear trend of decreasing loss and increasing accuracy in the first few epochs; otherwise, that is a red flag that your model has not been developed properly, thus, stop training, fix the issues and then train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Very Important Note**: Training NNs and DNNs take a lot of time and efforts, and you need to do lots of experiments. While the hints and the provided outputs can be helpful, you are responsible to explore, investigate, and try as many necessary steps and approaches as needed and use the discussions and contents of the lectures/textbook/slides to achieve the desired results and to get credit for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' build the baseline_model\n",
    "    be careful about the input_dim and the output layer specifications\n",
    "    start with a simple model and change the model hyperparameters as needed '''\n",
    "baseline_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\", input_shape=(48,)),\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(11, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                490       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                121       \n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' get the baseline_model summary '''\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' compile the baseline_model\n",
    "    be careful with the loss function, it should work with one-hot encoded labels\n",
    "    metric should be accuracy\n",
    "    you can choose your optimizer and learning_rate '''\n",
    "\n",
    "baseline_model.compile(optimizer=\"adam\",\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1463/1463 [==============================] - 1s 606us/step - loss: 2.0408 - accuracy: 0.2580\n",
      "Epoch 2/20\n",
      "1463/1463 [==============================] - 1s 583us/step - loss: 1.0180 - accuracy: 0.6337\n",
      "Epoch 3/20\n",
      "1463/1463 [==============================] - 1s 622us/step - loss: 0.7794 - accuracy: 0.7336\n",
      "Epoch 4/20\n",
      "1463/1463 [==============================] - 1s 610us/step - loss: 0.6343 - accuracy: 0.7743\n",
      "Epoch 5/20\n",
      "1463/1463 [==============================] - 1s 586us/step - loss: 0.5495 - accuracy: 0.8011\n",
      "Epoch 6/20\n",
      "1463/1463 [==============================] - 1s 579us/step - loss: 0.5025 - accuracy: 0.8083\n",
      "Epoch 7/20\n",
      "1463/1463 [==============================] - 1s 603us/step - loss: 0.4668 - accuracy: 0.8191\n",
      "Epoch 8/20\n",
      "1463/1463 [==============================] - 1s 581us/step - loss: 0.4481 - accuracy: 0.8204\n",
      "Epoch 9/20\n",
      "1463/1463 [==============================] - 1s 572us/step - loss: 0.4277 - accuracy: 0.8286\n",
      "Epoch 10/20\n",
      "1463/1463 [==============================] - 1s 578us/step - loss: 0.4209 - accuracy: 0.8306\n",
      "Epoch 11/20\n",
      "1463/1463 [==============================] - 1s 604us/step - loss: 0.3986 - accuracy: 0.8384\n",
      "Epoch 12/20\n",
      "1463/1463 [==============================] - 1s 592us/step - loss: 0.3866 - accuracy: 0.8467\n",
      "Epoch 13/20\n",
      "1463/1463 [==============================] - 1s 590us/step - loss: 0.3755 - accuracy: 0.8478\n",
      "Epoch 14/20\n",
      "1463/1463 [==============================] - 1s 683us/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 15/20\n",
      "1463/1463 [==============================] - 1s 619us/step - loss: 0.3566 - accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "1463/1463 [==============================] - 2s 1ms/step - loss: 0.3530 - accuracy: 0.8644\n",
      "Epoch 17/20\n",
      "1463/1463 [==============================] - 1s 662us/step - loss: 0.3439 - accuracy: 0.8646\n",
      "Epoch 18/20\n",
      "1463/1463 [==============================] - 1s 682us/step - loss: 0.3411 - accuracy: 0.8665\n",
      "Epoch 19/20\n",
      "1463/1463 [==============================] - 1s 665us/step - loss: 0.3323 - accuracy: 0.8705\n",
      "Epoch 20/20\n",
      "1463/1463 [==============================] - 1s 594us/step - loss: 0.3285 - accuracy: 0.8705\n"
     ]
    }
   ],
   "source": [
    "''' train the baseline_model on X_train, y_train with 20 epochs and a validation_split=0.1\n",
    "    You may increase number of epochs or use callbacks and early stopping if needed\n",
    "    The minimum required val_accuracy after the last epoch is 0.85 '''\n",
    "\n",
    "baseline_model_history = baseline_model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot the history with figsize=(10,5)\n",
    "    the plot should display the grid and the whole range of values for loss and accuracy '''\n",
    "\n",
    "temp = pd.DataFrame(baseline_model_history.history).plot(figsize=(10, 5))\n",
    "temp.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: After each training session, the model contains some trained weights, so if you want to make changes to your NN and re-run your experiments with a new random initilization of weights, you should re-run the build-model cell to clear and re-initialize the weights randomly, and then compile it again so that you can have a fresh restart of your updated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building `nn_clf` with 99% Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a working `baseline_model` with 85% `val_accuracy`, you should build a NN classifier `nn_clf` that can achieve a **test accuracy** of 99%. You can start with the same architecture of your `baseline_model` and increase the compleixty of `nn_clf` gradually if needed. Recall that some train/test splits are easier for the model to learn from, so if your accuracy is getting so close but not hitting 0.99, you may want to re-split train/test in addition to the changes you may want to make on your model.\n",
    "\n",
    "> **Note**: Any hint given in this notebook is just a suggestion and may or may not work with your model depending on the configurations of your model, so you should try as many different configurations, techniques, and approaches as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build nn_clf\n",
    "nn_clf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\", input_shape=(48,)),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(11, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Compile nn_clf - metric is 'accuracy' and be careful to choose the loss properly\n",
    "    Hint1: One of the hyperparameters you can change is the optimizer (Adam, RMSprop, SGD, ...)\n",
    "    Hint2: The other impactful hyperparameter is learning_rate '''\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "nn_clf.compile(optimizer=opt,\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1646/1646 [==============================] - 2s 800us/step - loss: 1.3127 - accuracy: 0.5308\n",
      "Epoch 2/80\n",
      "1646/1646 [==============================] - 1s 875us/step - loss: 0.4345 - accuracy: 0.8250\n",
      "Epoch 3/80\n",
      "1646/1646 [==============================] - 1s 774us/step - loss: 0.3705 - accuracy: 0.8505\n",
      "Epoch 4/80\n",
      "1646/1646 [==============================] - 1s 817us/step - loss: 0.3284 - accuracy: 0.8683\n",
      "Epoch 5/80\n",
      "1646/1646 [==============================] - 1s 851us/step - loss: 0.3009 - accuracy: 0.8817\n",
      "Epoch 6/80\n",
      "1646/1646 [==============================] - 1s 778us/step - loss: 0.2610 - accuracy: 0.8977\n",
      "Epoch 7/80\n",
      "1646/1646 [==============================] - 1s 831us/step - loss: 0.2382 - accuracy: 0.9093\n",
      "Epoch 8/80\n",
      "1646/1646 [==============================] - 1s 853us/step - loss: 0.2160 - accuracy: 0.9191\n",
      "Epoch 9/80\n",
      "1646/1646 [==============================] - 1s 866us/step - loss: 0.2007 - accuracy: 0.9254\n",
      "Epoch 10/80\n",
      "1646/1646 [==============================] - 1s 825us/step - loss: 0.1835 - accuracy: 0.9332\n",
      "Epoch 11/80\n",
      "1646/1646 [==============================] - 2s 989us/step - loss: 0.1571 - accuracy: 0.9436\n",
      "Epoch 12/80\n",
      "1646/1646 [==============================] - 1s 882us/step - loss: 0.1574 - accuracy: 0.9427\n",
      "Epoch 13/80\n",
      "1646/1646 [==============================] - 1s 849us/step - loss: 0.1377 - accuracy: 0.9517\n",
      "Epoch 14/80\n",
      "1646/1646 [==============================] - 1s 856us/step - loss: 0.1294 - accuracy: 0.9552\n",
      "Epoch 15/80\n",
      "1646/1646 [==============================] - 1s 817us/step - loss: 0.1219 - accuracy: 0.9582\n",
      "Epoch 16/80\n",
      "1646/1646 [==============================] - 1s 868us/step - loss: 0.1150 - accuracy: 0.9592\n",
      "Epoch 17/80\n",
      "1646/1646 [==============================] - 1s 849us/step - loss: 0.1050 - accuracy: 0.9629\n",
      "Epoch 18/80\n",
      "1646/1646 [==============================] - 1s 824us/step - loss: 0.0969 - accuracy: 0.9653\n",
      "Epoch 19/80\n",
      "1646/1646 [==============================] - 1s 884us/step - loss: 0.0931 - accuracy: 0.9663\n",
      "Epoch 20/80\n",
      "1646/1646 [==============================] - 1s 867us/step - loss: 0.0886 - accuracy: 0.9684\n",
      "Epoch 21/80\n",
      "1646/1646 [==============================] - 1s 826us/step - loss: 0.0912 - accuracy: 0.9672\n",
      "Epoch 22/80\n",
      "1646/1646 [==============================] - 1s 815us/step - loss: 0.0774 - accuracy: 0.9727\n",
      "Epoch 23/80\n",
      "1646/1646 [==============================] - 1s 782us/step - loss: 0.0793 - accuracy: 0.9700\n",
      "Epoch 24/80\n",
      "1646/1646 [==============================] - 1s 829us/step - loss: 0.0700 - accuracy: 0.9746\n",
      "Epoch 25/80\n",
      "1646/1646 [==============================] - 2s 970us/step - loss: 0.0732 - accuracy: 0.9727\n",
      "Epoch 26/80\n",
      "1646/1646 [==============================] - 1s 775us/step - loss: 0.0683 - accuracy: 0.9759\n",
      "Epoch 27/80\n",
      "1646/1646 [==============================] - 1s 845us/step - loss: 0.0641 - accuracy: 0.9770\n",
      "Epoch 28/80\n",
      "1646/1646 [==============================] - 1s 845us/step - loss: 0.0634 - accuracy: 0.9760\n",
      "Epoch 29/80\n",
      "1646/1646 [==============================] - 1s 857us/step - loss: 0.0618 - accuracy: 0.9775\n",
      "Epoch 30/80\n",
      "1646/1646 [==============================] - 1s 813us/step - loss: 0.0626 - accuracy: 0.9773\n",
      "Epoch 31/80\n",
      "1646/1646 [==============================] - 1s 745us/step - loss: 0.0508 - accuracy: 0.9820\n",
      "Epoch 32/80\n",
      "1646/1646 [==============================] - 1s 761us/step - loss: 0.0509 - accuracy: 0.9811\n",
      "Epoch 33/80\n",
      "1646/1646 [==============================] - 1s 760us/step - loss: 0.0597 - accuracy: 0.9777\n",
      "Epoch 34/80\n",
      "1646/1646 [==============================] - 1s 758us/step - loss: 0.0535 - accuracy: 0.9796\n",
      "Epoch 35/80\n",
      "1646/1646 [==============================] - 1s 770us/step - loss: 0.0497 - accuracy: 0.9818\n",
      "Epoch 36/80\n",
      "1646/1646 [==============================] - 1s 818us/step - loss: 0.0550 - accuracy: 0.9794\n",
      "Epoch 37/80\n",
      "1646/1646 [==============================] - 1s 842us/step - loss: 0.0462 - accuracy: 0.9836\n",
      "Epoch 38/80\n",
      "1646/1646 [==============================] - 1s 820us/step - loss: 0.0509 - accuracy: 0.9810\n",
      "Epoch 39/80\n",
      "1646/1646 [==============================] - 1s 848us/step - loss: 0.0398 - accuracy: 0.9857\n",
      "Epoch 40/80\n",
      "1646/1646 [==============================] - 1s 821us/step - loss: 0.0470 - accuracy: 0.9832\n",
      "Epoch 41/80\n",
      "1646/1646 [==============================] - 1s 826us/step - loss: 0.0451 - accuracy: 0.9843\n",
      "Epoch 42/80\n",
      "1646/1646 [==============================] - 1s 833us/step - loss: 0.0431 - accuracy: 0.9846\n",
      "Epoch 43/80\n",
      "1646/1646 [==============================] - 1s 831us/step - loss: 0.0413 - accuracy: 0.9848\n",
      "Epoch 44/80\n",
      "1646/1646 [==============================] - 1s 811us/step - loss: 0.0376 - accuracy: 0.9864\n",
      "Epoch 45/80\n",
      "1646/1646 [==============================] - 1s 781us/step - loss: 0.0370 - accuracy: 0.9868\n",
      "Epoch 46/80\n",
      "1646/1646 [==============================] - 1s 769us/step - loss: 0.0438 - accuracy: 0.9834\n",
      "Epoch 47/80\n",
      "1646/1646 [==============================] - 1s 811us/step - loss: 0.0409 - accuracy: 0.9845\n",
      "Epoch 48/80\n",
      "1646/1646 [==============================] - 1s 773us/step - loss: 0.0352 - accuracy: 0.9868\n",
      "Epoch 49/80\n",
      "1646/1646 [==============================] - 1s 831us/step - loss: 0.0409 - accuracy: 0.9848\n",
      "Epoch 50/80\n",
      "1646/1646 [==============================] - 1s 801us/step - loss: 0.0354 - accuracy: 0.9872\n",
      "Epoch 51/80\n",
      "1646/1646 [==============================] - 1s 790us/step - loss: 0.0333 - accuracy: 0.9879\n",
      "Epoch 52/80\n",
      "1646/1646 [==============================] - 1s 752us/step - loss: 0.0339 - accuracy: 0.9878\n",
      "Epoch 53/80\n",
      "1646/1646 [==============================] - 1s 765us/step - loss: 0.0381 - accuracy: 0.9856\n",
      "Epoch 54/80\n",
      "1646/1646 [==============================] - 1s 839us/step - loss: 0.0315 - accuracy: 0.9893\n",
      "Epoch 55/80\n",
      "1646/1646 [==============================] - 1s 867us/step - loss: 0.0378 - accuracy: 0.9867\n",
      "Epoch 56/80\n",
      "1646/1646 [==============================] - 1s 848us/step - loss: 0.0363 - accuracy: 0.9873\n",
      "Epoch 57/80\n",
      "1646/1646 [==============================] - 1s 827us/step - loss: 0.0294 - accuracy: 0.99000s - loss: 0.0291 - accuracy: \n",
      "Epoch 58/80\n",
      "1646/1646 [==============================] - 1s 821us/step - loss: 0.0359 - accuracy: 0.9874\n",
      "Epoch 59/80\n",
      "1646/1646 [==============================] - 1s 792us/step - loss: 0.0301 - accuracy: 0.9894\n",
      "Epoch 60/80\n",
      "1646/1646 [==============================] - 1s 825us/step - loss: 0.0266 - accuracy: 0.9905\n",
      "Epoch 61/80\n",
      "1646/1646 [==============================] - 1s 804us/step - loss: 0.0301 - accuracy: 0.9890\n",
      "Epoch 62/80\n",
      "1646/1646 [==============================] - 1s 791us/step - loss: 0.0273 - accuracy: 0.9905\n",
      "Epoch 63/80\n",
      "1646/1646 [==============================] - 1s 824us/step - loss: 0.0284 - accuracy: 0.9897\n",
      "Epoch 64/80\n",
      "1646/1646 [==============================] - 1s 834us/step - loss: 0.0308 - accuracy: 0.9890\n",
      "Epoch 65/80\n",
      "1646/1646 [==============================] - 1s 791us/step - loss: 0.0303 - accuracy: 0.9896\n",
      "Epoch 66/80\n",
      "1646/1646 [==============================] - 1s 779us/step - loss: 0.0270 - accuracy: 0.9901\n",
      "Epoch 67/80\n",
      "1646/1646 [==============================] - 1s 783us/step - loss: 0.0243 - accuracy: 0.9914\n",
      "Epoch 68/80\n",
      "1646/1646 [==============================] - 1s 744us/step - loss: 0.0289 - accuracy: 0.9898\n",
      "Epoch 69/80\n",
      "1646/1646 [==============================] - 1s 803us/step - loss: 0.0283 - accuracy: 0.9896\n",
      "Epoch 70/80\n",
      "1646/1646 [==============================] - 1s 793us/step - loss: 0.0284 - accuracy: 0.9899\n",
      "Epoch 71/80\n",
      "1646/1646 [==============================] - 1s 806us/step - loss: 0.0245 - accuracy: 0.9920\n",
      "Epoch 72/80\n",
      "1646/1646 [==============================] - 1s 804us/step - loss: 0.0282 - accuracy: 0.9898\n",
      "Epoch 73/80\n",
      "1646/1646 [==============================] - 1s 750us/step - loss: 0.0258 - accuracy: 0.9918\n",
      "Epoch 74/80\n",
      "1646/1646 [==============================] - 1s 782us/step - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 75/80\n",
      "1646/1646 [==============================] - 1s 801us/step - loss: 0.0324 - accuracy: 0.9886\n",
      "Epoch 76/80\n",
      "1646/1646 [==============================] - 1s 818us/step - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 77/80\n",
      "1646/1646 [==============================] - 2s 956us/step - loss: 0.0285 - accuracy: 0.9903\n",
      "Epoch 78/80\n",
      "1646/1646 [==============================] - 1s 893us/step - loss: 0.0241 - accuracy: 0.9922\n",
      "Epoch 79/80\n",
      "1646/1646 [==============================] - 1s 877us/step - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 80/80\n",
      "1646/1646 [==============================] - 1s 877us/step - loss: 0.0200 - accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "''' train nn_clf on X_train, y_train with validation_split=0.1\n",
    "     Hint: You may use EarlyStopping and set the patience parameter,\n",
    "     but then you should check in the following cell whether the test accuracy reaches to 0.99,\n",
    "     and make changes to compile and nn_clf hyperparameters if needed '''\n",
    "save_here = \"my_99_model.h5\"\n",
    "my_checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='accuracy',filepath=save_here, save_best_only=True)\n",
    "check_yourself = tf.keras.callbacks.EarlyStopping(monitor='accuracy',patience=10, restore_best_weights=True)\n",
    "#callbacks=[my_checkpoint, check_yourself],\n",
    "\n",
    "nn_clf_history = nn_clf.fit(X_train, y_train, callbacks=[my_checkpoint, check_yourself], epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot the history with a figsize of (10,5)\n",
    "    the plot should display the grid and the whole range of values for loss and accuracy '''\n",
    "temp = pd.DataFrame(nn_clf_history.history).plot(figsize=(10, 5))\n",
    "temp.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To evaluate the model, you should use `evaluate()` method on the test set `X_test`.\n",
    "\n",
    "> <font color='red'>**Test Accuracy Requirement**</font>: Your accuracy on `X_test` should be **0.99** (rounded with two decimal places). Otherwise, your `nn_clf` will get no points for this part, so you should fine-tune the hyperparametrs of your `nn_clf` (number of neurons, hidden layers, etc.) and `compile` (such as optimizer, learning rate, etc.) accordingly.\n",
    "\n",
    "> **Hint**: Keep in mind that the best model is not always the most complex model, it should best fit with your data. You should start with a simple model as you did with the `baseline_model`, and increase the model complexity (number of neurons and hidden layers) gradually and when/if needed.\n",
    "\n",
    "> Recall that each time you want to run a new training session by calling `.fit()` method, you should re-run the build `nn_clf` and `compile` cells to re-start with a fresh random initilization of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 0s 538us/step - loss: 0.0758 - accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "'''Rollback to lowest loss model'''\n",
    "nn_clf = tf.keras.models.load_model(save_here)\n",
    "\n",
    "# Evaluate nn_clf on X_test, y_test\n",
    "nn_clf_loss, nn_clf_test_accuracy = nn_clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required Test Accuracy: 0.99\n",
    "round(nn_clf_test_accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the Impact of Learning Rate on Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you're going to plot the impact of learning-rate on accuracy specifically. To do so and to avoid repeating the code, you should write a function `build_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(300, activation=\"relu\", input_shape=(48,)),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(11, activation=\"softmax\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The **learning rate range** that you're going to investigate is between [0.001, 0.01] inclusive with an increment step of 0.001. Use the optimizer and other hyperparatmeters of your choice that performed the best in your fine-tuning of `nn_clf` in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates range - the for loop of the following experiment will iterate over this array\n",
    "learning_rates = np.arange(0.001, 0.011, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(learning_rates))\n",
    "learning_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: For the following experiment, you should compile the model with `accuracy` as the metric, and use the same loss function that was used for `baseline_model` and `nn_clf` in each iteration of the `for` loop.\n",
    "\n",
    "> Running this cell may take a a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 2s 790us/step - loss: 1.2750 - accuracy: 0.5362\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 827us/step - loss: 0.4310 - accuracy: 0.8259\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 851us/step - loss: 0.3590 - accuracy: 0.8564\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 786us/step - loss: 0.3144 - accuracy: 0.8745\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 819us/step - loss: 0.2783 - accuracy: 0.8913\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 803us/step - loss: 0.2587 - accuracy: 0.8998\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 764us/step - loss: 0.2270 - accuracy: 0.9156\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 762us/step - loss: 0.2078 - accuracy: 0.9250\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 764us/step - loss: 0.1940 - accuracy: 0.9290\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 822us/step - loss: 0.1756 - accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 832us/step - loss: 0.1696 - accuracy: 0.9378\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 839us/step - loss: 0.1411 - accuracy: 0.9508\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 842us/step - loss: 0.1423 - accuracy: 0.9506\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 816us/step - loss: 0.1280 - accuracy: 0.9572\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 791us/step - loss: 0.1155 - accuracy: 0.9590\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 819us/step - loss: 0.1193 - accuracy: 0.9583\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 799us/step - loss: 0.1081 - accuracy: 0.9640\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 842us/step - loss: 0.0977 - accuracy: 0.9664\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 815us/step - loss: 0.0883 - accuracy: 0.9696\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 786us/step - loss: 0.0891 - accuracy: 0.9695\n",
      "183/183 [==============================] - 0s 534us/step - loss: 0.1001 - accuracy: 0.9653\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 2s 813us/step - loss: 1.1374 - accuracy: 0.5638\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 802us/step - loss: 0.4104 - accuracy: 0.8275\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.3301 - accuracy: 0.8610\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.2840 - accuracy: 0.8841\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 786us/step - loss: 0.2549 - accuracy: 0.8996\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 784us/step - loss: 0.2259 - accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 778us/step - loss: 0.2024 - accuracy: 0.9223\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 796us/step - loss: 0.1849 - accuracy: 0.9301\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 796us/step - loss: 0.1607 - accuracy: 0.9402\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 795us/step - loss: 0.1584 - accuracy: 0.9410\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 790us/step - loss: 0.1486 - accuracy: 0.9445\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 786us/step - loss: 0.1270 - accuracy: 0.9535\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 802us/step - loss: 0.1100 - accuracy: 0.9594\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 786us/step - loss: 0.1043 - accuracy: 0.9619\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 795us/step - loss: 0.1169 - accuracy: 0.9575\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 779us/step - loss: 0.0886 - accuracy: 0.9673\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 781us/step - loss: 0.0952 - accuracy: 0.9644\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 788us/step - loss: 0.0887 - accuracy: 0.9668\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 796us/step - loss: 0.0841 - accuracy: 0.9691\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 798us/step - loss: 0.0786 - accuracy: 0.9704\n",
      "183/183 [==============================] - 0s 529us/step - loss: 0.0976 - accuracy: 0.9727\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 2s 783us/step - loss: 1.0610 - accuracy: 0.5937\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 779us/step - loss: 0.3918 - accuracy: 0.8318\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 788us/step - loss: 0.3232 - accuracy: 0.8665\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 781us/step - loss: 0.2782 - accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 792us/step - loss: 0.2534 - accuracy: 0.8998\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 855us/step - loss: 0.2175 - accuracy: 0.9144\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 833us/step - loss: 0.1798 - accuracy: 0.9310\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 791us/step - loss: 0.1529 - accuracy: 0.9431\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 780us/step - loss: 0.1489 - accuracy: 0.9447\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 769us/step - loss: 0.1349 - accuracy: 0.9498\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 781us/step - loss: 0.1250 - accuracy: 0.9536\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 769us/step - loss: 0.1144 - accuracy: 0.9586\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 753us/step - loss: 0.1073 - accuracy: 0.9590\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 767us/step - loss: 0.1040 - accuracy: 0.9618\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 758us/step - loss: 0.1009 - accuracy: 0.9633\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 769us/step - loss: 0.0874 - accuracy: 0.9674\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 778us/step - loss: 0.0920 - accuracy: 0.9662\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.0861 - accuracy: 0.9683\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 777us/step - loss: 0.0824 - accuracy: 0.9708\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 753us/step - loss: 0.0906 - accuracy: 0.9663\n",
      "183/183 [==============================] - 0s 526us/step - loss: 0.1169 - accuracy: 0.9704\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 1s 765us/step - loss: 1.0687 - accuracy: 0.5730\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 776us/step - loss: 0.4030 - accuracy: 0.8251\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 766us/step - loss: 0.3453 - accuracy: 0.8554\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 856us/step - loss: 0.2914 - accuracy: 0.8832\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 854us/step - loss: 0.2562 - accuracy: 0.8962\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 857us/step - loss: 0.2247 - accuracy: 0.9118\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 837us/step - loss: 0.2079 - accuracy: 0.9198\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 839us/step - loss: 0.1678 - accuracy: 0.9361\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 820us/step - loss: 0.1542 - accuracy: 0.9445\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 799us/step - loss: 0.1543 - accuracy: 0.9426\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 810us/step - loss: 0.1372 - accuracy: 0.9497\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 784us/step - loss: 0.1260 - accuracy: 0.9528\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 815us/step - loss: 0.1204 - accuracy: 0.9556\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 766us/step - loss: 0.0998 - accuracy: 0.9640\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 775us/step - loss: 0.0905 - accuracy: 0.9666\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 769us/step - loss: 0.0919 - accuracy: 0.9655\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 743us/step - loss: 0.0974 - accuracy: 0.9635\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 770us/step - loss: 0.0901 - accuracy: 0.9671\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 781us/step - loss: 0.0900 - accuracy: 0.9673\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 763us/step - loss: 0.0892 - accuracy: 0.9674\n",
      "183/183 [==============================] - 0s 491us/step - loss: 0.1598 - accuracy: 0.9508\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 1s 753us/step - loss: 1.0378 - accuracy: 0.5842\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 762us/step - loss: 0.4268 - accuracy: 0.8177\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 750us/step - loss: 0.3649 - accuracy: 0.8468\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 737us/step - loss: 0.3255 - accuracy: 0.8656\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 753us/step - loss: 0.2682 - accuracy: 0.8920\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 761us/step - loss: 0.2436 - accuracy: 0.9040\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 741us/step - loss: 0.2083 - accuracy: 0.9184\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 738us/step - loss: 0.1905 - accuracy: 0.9284\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 747us/step - loss: 0.1600 - accuracy: 0.9396\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 744us/step - loss: 0.1492 - accuracy: 0.9422\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 743us/step - loss: 0.1367 - accuracy: 0.9475\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 760us/step - loss: 0.1179 - accuracy: 0.9554\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 750us/step - loss: 0.1090 - accuracy: 0.9603\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 759us/step - loss: 0.1022 - accuracy: 0.9612\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 757us/step - loss: 0.0936 - accuracy: 0.9636\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 754us/step - loss: 0.0952 - accuracy: 0.9657\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 754us/step - loss: 0.0731 - accuracy: 0.9725\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 752us/step - loss: 0.0940 - accuracy: 0.9660\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 754us/step - loss: 0.0761 - accuracy: 0.9725\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 741us/step - loss: 0.0971 - accuracy: 0.9649\n",
      "183/183 [==============================] - 0s 497us/step - loss: 0.0891 - accuracy: 0.9757\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 1s 754us/step - loss: 1.0405 - accuracy: 0.5706\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 756us/step - loss: 0.4271 - accuracy: 0.8172\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 751us/step - loss: 0.3686 - accuracy: 0.8510\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 762us/step - loss: 0.2850 - accuracy: 0.8850\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 751us/step - loss: 0.2330 - accuracy: 0.9082\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 753us/step - loss: 0.2070 - accuracy: 0.9208\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 751us/step - loss: 0.2010 - accuracy: 0.9233\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 757us/step - loss: 0.1546 - accuracy: 0.9431\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 756us/step - loss: 0.1640 - accuracy: 0.9374\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 757us/step - loss: 0.1710 - accuracy: 0.9364\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 746us/step - loss: 0.1392 - accuracy: 0.9493\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 754us/step - loss: 0.1341 - accuracy: 0.9507\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 802us/step - loss: 0.1297 - accuracy: 0.9521\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 836us/step - loss: 0.1210 - accuracy: 0.9558\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 899us/step - loss: 0.1132 - accuracy: 0.9574\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 2s 970us/step - loss: 0.1232 - accuracy: 0.9552\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 819us/step - loss: 0.0988 - accuracy: 0.9627\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 839us/step - loss: 0.0873 - accuracy: 0.9689\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 866us/step - loss: 0.1114 - accuracy: 0.9611\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 869us/step - loss: 0.1062 - accuracy: 0.9625\n",
      "183/183 [==============================] - 0s 526us/step - loss: 0.0706 - accuracy: 0.9834\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 2s 807us/step - loss: 0.9847 - accuracy: 0.5991\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 847us/step - loss: 0.4286 - accuracy: 0.8191\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 819us/step - loss: 0.3564 - accuracy: 0.8522\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 816us/step - loss: 0.2960 - accuracy: 0.8757\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 758us/step - loss: 0.2752 - accuracy: 0.8911\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 789us/step - loss: 0.2448 - accuracy: 0.9022\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.2213 - accuracy: 0.9126\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 802us/step - loss: 0.2011 - accuracy: 0.9227\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 777us/step - loss: 0.1785 - accuracy: 0.9315\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 784us/step - loss: 0.1750 - accuracy: 0.9339\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 793us/step - loss: 0.1554 - accuracy: 0.9408\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 783us/step - loss: 0.1201 - accuracy: 0.9557\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 788us/step - loss: 0.1407 - accuracy: 0.9467\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 784us/step - loss: 0.1187 - accuracy: 0.9542\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 794us/step - loss: 0.1279 - accuracy: 0.9538\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 794us/step - loss: 0.0989 - accuracy: 0.9635\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.1250 - accuracy: 0.9564\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 802us/step - loss: 0.1029 - accuracy: 0.9619\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 795us/step - loss: 0.1011 - accuracy: 0.9638\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 805us/step - loss: 0.0999 - accuracy: 0.9637\n",
      "183/183 [==============================] - 0s 562us/step - loss: 0.1619 - accuracy: 0.9516\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 2s 783us/step - loss: 1.0267 - accuracy: 0.5761\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 790us/step - loss: 0.4310 - accuracy: 0.8131\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 777us/step - loss: 0.3583 - accuracy: 0.8480\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.2992 - accuracy: 0.8775\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 786us/step - loss: 0.2812 - accuracy: 0.8874\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 798us/step - loss: 0.2488 - accuracy: 0.9016\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 787us/step - loss: 0.2133 - accuracy: 0.9152\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 789us/step - loss: 0.1955 - accuracy: 0.9226\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 795us/step - loss: 0.1875 - accuracy: 0.9259\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 799us/step - loss: 0.1862 - accuracy: 0.9279\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 1s 753us/step - loss: 0.1909 - accuracy: 0.9300\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 763us/step - loss: 0.1424 - accuracy: 0.9476\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 731us/step - loss: 0.1511 - accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 733us/step - loss: 0.1344 - accuracy: 0.9494\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 738us/step - loss: 0.1250 - accuracy: 0.9519\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 727us/step - loss: 0.1264 - accuracy: 0.9522\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 739us/step - loss: 0.1127 - accuracy: 0.9581\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 729us/step - loss: 0.1180 - accuracy: 0.9560\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 732us/step - loss: 0.1271 - accuracy: 0.9561\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 740us/step - loss: 0.1097 - accuracy: 0.9588\n",
      "183/183 [==============================] - 0s 518us/step - loss: 0.1519 - accuracy: 0.9786\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 1s 745us/step - loss: 0.9424 - accuracy: 0.6163\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 745us/step - loss: 0.4269 - accuracy: 0.8161\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 827us/step - loss: 0.3829 - accuracy: 0.8339\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 832us/step - loss: 0.3190 - accuracy: 0.8672\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 835us/step - loss: 0.2998 - accuracy: 0.8782\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 779us/step - loss: 0.2675 - accuracy: 0.8935\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 776us/step - loss: 0.2369 - accuracy: 0.9058\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 772us/step - loss: 0.2045 - accuracy: 0.9202\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 759us/step - loss: 0.1967 - accuracy: 0.9247\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 806us/step - loss: 0.2200 - accuracy: 0.9187\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 797us/step - loss: 0.1635 - accuracy: 0.9388\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 792us/step - loss: 0.1743 - accuracy: 0.9361\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 780us/step - loss: 0.1458 - accuracy: 0.9450\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 782us/step - loss: 0.1409 - accuracy: 0.9492\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 773us/step - loss: 0.1405 - accuracy: 0.9475\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 764us/step - loss: 0.1342 - accuracy: 0.9495\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 789us/step - loss: 0.1334 - accuracy: 0.9504\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 782us/step - loss: 0.1338 - accuracy: 0.9521\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 781us/step - loss: 0.1160 - accuracy: 0.9560\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 789us/step - loss: 0.1120 - accuracy: 0.9589\n",
      "183/183 [==============================] - 0s 546us/step - loss: 0.1104 - accuracy: 0.9727\n",
      "Epoch 1/20\n",
      "1646/1646 [==============================] - 2s 785us/step - loss: 1.0903 - accuracy: 0.5460\n",
      "Epoch 2/20\n",
      "1646/1646 [==============================] - 1s 787us/step - loss: 0.4520 - accuracy: 0.8055\n",
      "Epoch 3/20\n",
      "1646/1646 [==============================] - 1s 780us/step - loss: 0.3657 - accuracy: 0.8419\n",
      "Epoch 4/20\n",
      "1646/1646 [==============================] - 1s 802us/step - loss: 0.3361 - accuracy: 0.8558\n",
      "Epoch 5/20\n",
      "1646/1646 [==============================] - 1s 792us/step - loss: 0.3217 - accuracy: 0.8678\n",
      "Epoch 6/20\n",
      "1646/1646 [==============================] - 1s 789us/step - loss: 0.2978 - accuracy: 0.8803\n",
      "Epoch 7/20\n",
      "1646/1646 [==============================] - 1s 779us/step - loss: 0.2758 - accuracy: 0.8914\n",
      "Epoch 8/20\n",
      "1646/1646 [==============================] - 1s 824us/step - loss: 0.2629 - accuracy: 0.9005\n",
      "Epoch 9/20\n",
      "1646/1646 [==============================] - 1s 832us/step - loss: 0.2043 - accuracy: 0.9230\n",
      "Epoch 10/20\n",
      "1646/1646 [==============================] - 1s 792us/step - loss: 0.2041 - accuracy: 0.9242\n",
      "Epoch 11/20\n",
      "1646/1646 [==============================] - 1s 824us/step - loss: 0.2053 - accuracy: 0.9232\n",
      "Epoch 12/20\n",
      "1646/1646 [==============================] - 1s 856us/step - loss: 0.1735 - accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "1646/1646 [==============================] - 1s 844us/step - loss: 0.1846 - accuracy: 0.9323\n",
      "Epoch 14/20\n",
      "1646/1646 [==============================] - 1s 843us/step - loss: 0.1813 - accuracy: 0.9346\n",
      "Epoch 15/20\n",
      "1646/1646 [==============================] - 1s 836us/step - loss: 0.1618 - accuracy: 0.9417\n",
      "Epoch 16/20\n",
      "1646/1646 [==============================] - 1s 818us/step - loss: 0.1539 - accuracy: 0.9450\n",
      "Epoch 17/20\n",
      "1646/1646 [==============================] - 1s 785us/step - loss: 0.1531 - accuracy: 0.9453\n",
      "Epoch 18/20\n",
      "1646/1646 [==============================] - 1s 787us/step - loss: 0.1612 - accuracy: 0.9407\n",
      "Epoch 19/20\n",
      "1646/1646 [==============================] - 1s 771us/step - loss: 0.1522 - accuracy: 0.9453\n",
      "Epoch 20/20\n",
      "1646/1646 [==============================] - 1s 758us/step - loss: 0.1487 - accuracy: 0.9474\n",
      "183/183 [==============================] - 0s 571us/step - loss: 0.2125 - accuracy: 0.9547\n"
     ]
    }
   ],
   "source": [
    "# accuracies list\n",
    "accuracies = []\n",
    "\n",
    "''' Write a for loop that iterates over learning_rates array which was defined in the previous cell\n",
    "    In each iteration:\n",
    "        build a new model by calling build_model(),\n",
    "        compile with the optimizer of your choice, and the current learning_rate in this iteration,\n",
    "        train on X_train and y_train with 20 epochs,\n",
    "        evaluate the model on X_test, y_test and get the test accuracy,\n",
    "        append the test accuracy to the accuracies list '''\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    this_model = build_model()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    this_model.compile(optimizer=opt,\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "    history_this_model = this_model.fit(X_train, y_train, epochs=20)\n",
    "    this_model_loss, this_model_test_accuracy = this_model.evaluate(X_test, y_test)\n",
    "    accuracies.append(this_model_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd15d894070>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Plot the \"Impact of Learning Rate on Accuracy\" with 'Learning Rate' on x-axis and 'Accuracy' on y_axis\n",
    "    The plot should use 'seaborn' style and with a figsize=(10, 5) and fontsize=14 for the title/labels\n",
    "    The plot must have title, axis labels, and xticks precisely as specified and displayed below\n",
    "    \n",
    "    The range of your accuracies may slightly differ but should be similar, and\n",
    "    the range of learning rate should be exactly the same, i.e from 0.001 to 0.01\n",
    "    \n",
    "    Incomplete/wrong plots will get no credit '''\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.style.use(\"seaborn-dark\")\n",
    "plt.grid(True)\n",
    "plt.xticks(np.arange(0.001, 0.011, step=0.001))\n",
    "plt.title(\"Impact of Learning Rate on Accuracy\",fontsize=14)\n",
    "plt.xlabel(\"Learning Rate\",fontsize=14)\n",
    "plt.ylabel(\"Accuracy\",fontsize=14)\n",
    "plt.plot(learning_rates, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-I - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER THE FOLLOWING QUESTIONS HERE:\n",
    "\n",
    "**Q1 [5 points]** - According to your plot of accuracy vs learning rate, what is a good value for learning rate? **Why**? Mention the reason clearly.\n",
    "\n",
    "    A1. According to the above plot of accuracy vs learning rate, there appears to be peaks and vallys that the Adam optimzer likes. The plot above should be a reflection of the loss function's topography interacting with the optimizer's (Adam's) stochastic nature. Suppose the loss function's topography has a dominant slope value that harmonizes well with learning rate = 0.005, but creates a \"negative feedback\" for learning rate = 0.007. That is, if the valley walls are spaced apart just so, the learning rate may see the stochastic behavior of Adam more often jump to a higher point in the loss functions topography instead of a lower point closer to the global minimum.  \n",
    "\n",
    "**Q2 [5 points]** - Name five learning rate scheduling policies known as **learning schedules** (you may consult with the textbook), and explain each briefly in no more than two sentences here.\n",
    "\n",
    "    A2. Power scheduling: Set an initial learning rate, Eta_0, and then iterate the variable t. At first this will rapidly halve the learning rate, then more gradually halve again, and again more gradually. This schedule is defined by the function: eta(t) = eta_0/(1+t/s)^c\n",
    "    \n",
    "    Exponential Scheduling: This scheduling function is defined as follows: eta(t) = eta_0 * 0.1^(t/s). Whatever our initial learning schedule eta_0, mulitiplying it by first a franction of a root, then the first root, then the square root, etc. of 0.1 means we slash the learning rate by a factor of 10 for every s'th interation. \n",
    "    \n",
    "    Piecewise Constant Scheduling: This is the most handcrafted of the learning schedules. Basically the engineer will determine the learning rate that will be applied and for how long. The engineer may string disparate learning rates and durations pairs together to form a sequencer remeniscent of a piecewise function. \n",
    "    I.e. eta(t) ={ eta_0 = 0.1 for 5 epochs,\n",
    "                    eta_0 = 0.001 for the next 50 epochs }\n",
    "                    \n",
    "    Performance Scheduling: This Schedule incorporates the validation error measurment. This measurement is reference every N steps or epochs, and when the error stops dropping then the learning rate is reduced by a factor of lamda. \n",
    "    \n",
    "    1cycle Scheduling: For 1cycle scheduling, we take an optimal learning rate, eta_1, and a learning rate roughly 1/10 of that, eta_0. For the first half of the training epochs, the learning rate is increased linearly from eta_0 to eta_1. Then the learning rate is decreased linearly from eta_1 to eta_0 during the second half of the training epochs. This idea can be used with momentum instead of learning rate, only we start with a high momentum and decrease the momentum for the first half of training and increase momentum for the second half of training. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-II - Regression Using NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part-II, you're going to perform a regression task using NN that you build in Tensorflow/Keras framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [\"Video Game Sales with Ratings\"](https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings) dataset and read the descriptions on the Kaggle page. You are going to build and train a regression NN to predict **`NA_Sales`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16719, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the 'Video_Games_Sales_as_at_22_Dec_2016.csv' as a dataframe using pandas\n",
    "data2 = pd.read_csv(\"Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the multiple steps of preprocessing very carefully.\n",
    "\n",
    "**NOTE**: If you do not perform the preprocessing steps correctly, all of your results would be wrong and your Part-II will get zero points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As usual, check if there is any NAs (there are plenty) and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  2\n",
       "Platform              0\n",
       "Year_of_Release     269\n",
       "Genre                 2\n",
       "Publisher            54\n",
       "NA_Sales              0\n",
       "EU_Sales              0\n",
       "JP_Sales              0\n",
       "Other_Sales           0\n",
       "Global_Sales          0\n",
       "Critic_Score       8582\n",
       "Critic_Count       8582\n",
       "User_Score         6704\n",
       "User_Count         9129\n",
       "Developer          6623\n",
       "Rating             6769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NAs\n",
    "data2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Super Mario Bros.</td>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wii Play</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Platform  Year_of_Release     Genre Publisher  \\\n",
       "0             Wii Sports      Wii           2006.0    Sports  Nintendo   \n",
       "2         Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
       "3      Wii Sports Resort      Wii           2009.0    Sports  Nintendo   \n",
       "6  New Super Mario Bros.       DS           2006.0  Platform  Nintendo   \n",
       "7               Wii Play      Wii           2006.0      Misc  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "6     11.28      9.14      6.50         2.88         29.80          89.0   \n",
       "7     13.96      9.18      2.93         2.84         28.92          58.0   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "6          65.0        8.5       431.0  Nintendo      E  \n",
       "7          41.0        6.6       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NAs\n",
    "data2.dropna(inplace=True)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Platform           0\n",
       "Year_of_Release    0\n",
       "Genre              0\n",
       "Publisher          0\n",
       "NA_Sales           0\n",
       "EU_Sales           0\n",
       "JP_Sales           0\n",
       "Other_Sales        0\n",
       "Global_Sales       0\n",
       "Critic_Score       0\n",
       "Critic_Count       0\n",
       "User_Score         0\n",
       "User_Count         0\n",
       "Developer          0\n",
       "Rating             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NAs again\n",
    "data2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since there were a lot of NAs, you've missed a lot of indexes of the dropped rows after dropping NAs, so you should use [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) but no new column should be added as `index`, so you should set the `drop` parameter of `reset_index()` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Super Mario Bros.</td>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wii Play</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Platform  Year_of_Release     Genre Publisher  \\\n",
       "0             Wii Sports      Wii           2006.0    Sports  Nintendo   \n",
       "1         Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
       "2      Wii Sports Resort      Wii           2009.0    Sports  Nintendo   \n",
       "3  New Super Mario Bros.       DS           2006.0  Platform  Nintendo   \n",
       "4               Wii Play      Wii           2006.0      Misc  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "2     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "3     11.28      9.14      6.50         2.88         29.80          89.0   \n",
       "4     13.96      9.18      2.93         2.84         28.92          58.0   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1          73.0        8.3       709.0  Nintendo      E  \n",
       "2          73.0          8       192.0  Nintendo      E  \n",
       "3          65.0        8.5       431.0  Nintendo      E  \n",
       "4          41.0        6.6       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index so that the rows are indexed from 0 and increment by one, no column should be added!\n",
    "data2.reset_index(drop=True, inplace=True)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     41.36     28.96      3.77   \n",
       "1      Wii           2008.0    Racing  Nintendo     15.68     12.76      3.79   \n",
       "2      Wii           2009.0    Sports  Nintendo     15.61     10.93      3.28   \n",
       "3       DS           2006.0  Platform  Nintendo     11.28      9.14      6.50   \n",
       "4      Wii           2006.0      Misc  Nintendo     13.96      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Global_Sales  Critic_Score  Critic_Count User_Score  \\\n",
       "0         8.45         82.53          76.0          51.0          8   \n",
       "1         3.29         35.52          82.0          73.0        8.3   \n",
       "2         2.95         32.77          80.0          73.0          8   \n",
       "3         2.88         29.80          89.0          65.0        8.5   \n",
       "4         2.84         28.92          58.0          41.0        6.6   \n",
       "\n",
       "   User_Count Developer Rating  \n",
       "0       322.0  Nintendo      E  \n",
       "1       709.0  Nintendo      E  \n",
       "2       192.0  Nintendo      E  \n",
       "3       431.0  Nintendo      E  \n",
       "4       129.0  Nintendo      E  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Name\" column as it does not provide useful info for your model training\n",
    "data2.drop(columns='Name', inplace=True)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `NA_Sales` is the target column for prediction; however, since the column `Global_Sales` is the sum of other sales, you should drop it; otherwise, it corrupts the training process by leaking information and violating the regression assumption that features are independent.\n",
    "\n",
    "> **NOTE**: Make sure to match your `data2` dataframe with the provided outputs after every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     41.36     28.96      3.77   \n",
       "1      Wii           2008.0    Racing  Nintendo     15.68     12.76      3.79   \n",
       "2      Wii           2009.0    Sports  Nintendo     15.61     10.93      3.28   \n",
       "3       DS           2006.0  Platform  Nintendo     11.28      9.14      6.50   \n",
       "4      Wii           2006.0      Misc  Nintendo     13.96      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Critic_Score  Critic_Count User_Score  User_Count Developer  \\\n",
       "0         8.45          76.0          51.0          8       322.0  Nintendo   \n",
       "1         3.29          82.0          73.0        8.3       709.0  Nintendo   \n",
       "2         2.95          80.0          73.0          8       192.0  Nintendo   \n",
       "3         2.88          89.0          65.0        8.5       431.0  Nintendo   \n",
       "4         2.84          58.0          41.0        6.6       129.0  Nintendo   \n",
       "\n",
       "  Rating  \n",
       "0      E  \n",
       "1      E  \n",
       "2      E  \n",
       "3      E  \n",
       "4      E  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Global_Sales\" column\n",
    "data2.drop(columns='Global_Sales', inplace=True)\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, check the statistical description of `NA_Sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6825.000000\n",
       "mean        0.394484\n",
       "std         0.967385\n",
       "min         0.000000\n",
       "25%         0.060000\n",
       "50%         0.150000\n",
       "75%         0.390000\n",
       "max        41.360000\n",
       "Name: NA_Sales, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['NA_Sales'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year_of_Release   -0.016239\n",
       "Critic_Score       0.233580\n",
       "User_Count         0.246208\n",
       "Critic_Count       0.283917\n",
       "JP_Sales           0.468607\n",
       "Other_Sales        0.726757\n",
       "EU_Sales           0.841808\n",
       "NA_Sales           1.000000\n",
       "Name: NA_Sales, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find correlations with NA_Sales\n",
    "correlations = data2.corr()[\"NA_Sales\"].sort_values()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate features from the target column, so `X2` should contain all columns except `NA_Sales`. `y2` should contain `NA_Sales` only. `X2` and `y2` are so named to differentiate them from the features and labels of Part-I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature vector X2 (all columns but \"NA_Sales\") and target label y2 as \"NA_Sales\"\n",
    "X2 = data2[['Platform','Year_of_Release','Genre','Publisher','EU_Sales','JP_Sales','Other_Sales','Critic_Score','Critic_Count','User_Score','User_Count','Developer','Rating']]\n",
    "y2 = data2['NA_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>431.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform  Year_of_Release     Genre Publisher  EU_Sales  JP_Sales  \\\n",
       "0      Wii           2006.0    Sports  Nintendo     28.96      3.77   \n",
       "1      Wii           2008.0    Racing  Nintendo     12.76      3.79   \n",
       "2      Wii           2009.0    Sports  Nintendo     10.93      3.28   \n",
       "3       DS           2006.0  Platform  Nintendo      9.14      6.50   \n",
       "4      Wii           2006.0      Misc  Nintendo      9.18      2.93   \n",
       "\n",
       "   Other_Sales  Critic_Score  Critic_Count User_Score  User_Count Developer  \\\n",
       "0         8.45          76.0          51.0          8       322.0  Nintendo   \n",
       "1         3.29          82.0          73.0        8.3       709.0  Nintendo   \n",
       "2         2.95          80.0          73.0          8       192.0  Nintendo   \n",
       "3         2.88          89.0          65.0        8.5       431.0  Nintendo   \n",
       "4         2.84          58.0          41.0        6.6       129.0  Nintendo   \n",
       "\n",
       "  Rating  \n",
       "0      E  \n",
       "1      E  \n",
       "2      E  \n",
       "3      E  \n",
       "4      E  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print X2 shape and head\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    41.36\n",
       "1    15.68\n",
       "2    15.61\n",
       "3    11.28\n",
       "4    13.96\n",
       "Name: NA_Sales, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print y2 shape and head\n",
    "print(y2.shape)\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform            object\n",
       "Year_of_Release    float64\n",
       "Genre               object\n",
       "Publisher           object\n",
       "EU_Sales           float64\n",
       "JP_Sales           float64\n",
       "Other_Sales        float64\n",
       "Critic_Score       float64\n",
       "Critic_Count       float64\n",
       "User_Score          object\n",
       "User_Count         float64\n",
       "Developer           object\n",
       "Rating              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You should convert `object` (categorical) features using [`get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html). This will increase the number of features to **1683** by one-hot encoding. You can simply call `get_dummies()` on `X2` directly, and it will detect the `object` features and one-hot encode them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 1683)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Platform_3DS</th>\n",
       "      <th>Platform_DC</th>\n",
       "      <th>Platform_DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Developer_odenis studio</th>\n",
       "      <th>Developer_syn Sophia</th>\n",
       "      <th>Developer_zSlide</th>\n",
       "      <th>Rating_AO</th>\n",
       "      <th>Rating_E</th>\n",
       "      <th>Rating_E10+</th>\n",
       "      <th>Rating_K-A</th>\n",
       "      <th>Rating_M</th>\n",
       "      <th>Rating_RP</th>\n",
       "      <th>Rating_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>89.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release  EU_Sales  JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0           2006.0     28.96      3.77         8.45          76.0   \n",
       "1           2008.0     12.76      3.79         3.29          82.0   \n",
       "2           2009.0     10.93      3.28         2.95          80.0   \n",
       "3           2006.0      9.14      6.50         2.88          89.0   \n",
       "4           2006.0      9.18      2.93         2.84          58.0   \n",
       "\n",
       "   Critic_Count  User_Count  Platform_3DS  Platform_DC  Platform_DS  ...  \\\n",
       "0          51.0       322.0             0            0            0  ...   \n",
       "1          73.0       709.0             0            0            0  ...   \n",
       "2          73.0       192.0             0            0            0  ...   \n",
       "3          65.0       431.0             0            0            1  ...   \n",
       "4          41.0       129.0             0            0            0  ...   \n",
       "\n",
       "   Developer_odenis studio  Developer_syn Sophia  Developer_zSlide  Rating_AO  \\\n",
       "0                        0                     0                 0          0   \n",
       "1                        0                     0                 0          0   \n",
       "2                        0                     0                 0          0   \n",
       "3                        0                     0                 0          0   \n",
       "4                        0                     0                 0          0   \n",
       "\n",
       "   Rating_E  Rating_E10+  Rating_K-A  Rating_M  Rating_RP  Rating_T  \n",
       "0         1            0           0         0          0         0  \n",
       "1         1            0           0         0          0         0  \n",
       "2         1            0           0         0          0         0  \n",
       "3         1            0           0         0          0         0  \n",
       "4         1            0           0         0          0         0  \n",
       "\n",
       "[5 rows x 1683 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas.get_dummies() create dummy variables for categorical features (needs 1 line of code only)\n",
    "X2 = pd.get_dummies(X2)\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 1683)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Platform_3DS</th>\n",
       "      <th>Platform_DC</th>\n",
       "      <th>Platform_DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Developer_odenis studio</th>\n",
       "      <th>Developer_syn Sophia</th>\n",
       "      <th>Developer_zSlide</th>\n",
       "      <th>Rating_AO</th>\n",
       "      <th>Rating_E</th>\n",
       "      <th>Rating_E10+</th>\n",
       "      <th>Rating_K-A</th>\n",
       "      <th>Rating_M</th>\n",
       "      <th>Rating_RP</th>\n",
       "      <th>Rating_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.341176</td>\n",
       "      <td>41.790569</td>\n",
       "      <td>12.886767</td>\n",
       "      <td>31.004904</td>\n",
       "      <td>0.413014</td>\n",
       "      <td>1.147975</td>\n",
       "      <td>0.250716</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>-0.045334</td>\n",
       "      <td>-0.270063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>1.509226</td>\n",
       "      <td>-0.397162</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.515485</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133743</td>\n",
       "      <td>18.221103</td>\n",
       "      <td>12.956315</td>\n",
       "      <td>11.884655</td>\n",
       "      <td>0.845647</td>\n",
       "      <td>2.292368</td>\n",
       "      <td>0.909519</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>-0.045334</td>\n",
       "      <td>-0.270063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>1.509226</td>\n",
       "      <td>-0.397162</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.515485</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.371202</td>\n",
       "      <td>15.558627</td>\n",
       "      <td>11.182831</td>\n",
       "      <td>10.624793</td>\n",
       "      <td>0.701436</td>\n",
       "      <td>2.292368</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>-0.045334</td>\n",
       "      <td>-0.270063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>1.509226</td>\n",
       "      <td>-0.397162</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.515485</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.341176</td>\n",
       "      <td>12.954346</td>\n",
       "      <td>22.380122</td>\n",
       "      <td>10.365410</td>\n",
       "      <td>1.350385</td>\n",
       "      <td>1.876225</td>\n",
       "      <td>0.436270</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>-0.045334</td>\n",
       "      <td>3.702302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>1.509226</td>\n",
       "      <td>-0.397162</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.515485</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.341176</td>\n",
       "      <td>13.012543</td>\n",
       "      <td>9.965734</td>\n",
       "      <td>10.217191</td>\n",
       "      <td>-0.884885</td>\n",
       "      <td>0.627797</td>\n",
       "      <td>-0.077835</td>\n",
       "      <td>-0.15243</td>\n",
       "      <td>-0.045334</td>\n",
       "      <td>-0.270063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.01712</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>1.509226</td>\n",
       "      <td>-0.397162</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.515485</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.730971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release   EU_Sales   JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0        -0.341176  41.790569  12.886767    31.004904      0.413014   \n",
       "1         0.133743  18.221103  12.956315    11.884655      0.845647   \n",
       "2         0.371202  15.558627  11.182831    10.624793      0.701436   \n",
       "3        -0.341176  12.954346  22.380122    10.365410      1.350385   \n",
       "4        -0.341176  13.012543   9.965734    10.217191     -0.884885   \n",
       "\n",
       "   Critic_Count  User_Count  Platform_3DS  Platform_DC  Platform_DS  ...  \\\n",
       "0      1.147975    0.250716      -0.15243    -0.045334    -0.270063  ...   \n",
       "1      2.292368    0.909519      -0.15243    -0.045334    -0.270063  ...   \n",
       "2      2.292368    0.029412      -0.15243    -0.045334    -0.270063  ...   \n",
       "3      1.876225    0.436270      -0.15243    -0.045334     3.702302  ...   \n",
       "4      0.627797   -0.077835      -0.15243    -0.045334    -0.270063  ...   \n",
       "\n",
       "   Developer_odenis studio  Developer_syn Sophia  Developer_zSlide  Rating_AO  \\\n",
       "0                -0.012105              -0.01712         -0.012105  -0.012105   \n",
       "1                -0.012105              -0.01712         -0.012105  -0.012105   \n",
       "2                -0.012105              -0.01712         -0.012105  -0.012105   \n",
       "3                -0.012105              -0.01712         -0.012105  -0.012105   \n",
       "4                -0.012105              -0.01712         -0.012105  -0.012105   \n",
       "\n",
       "   Rating_E  Rating_E10+  Rating_K-A  Rating_M  Rating_RP  Rating_T  \n",
       "0  1.509226    -0.397162   -0.012105 -0.515485  -0.012105 -0.730971  \n",
       "1  1.509226    -0.397162   -0.012105 -0.515485  -0.012105 -0.730971  \n",
       "2  1.509226    -0.397162   -0.012105 -0.515485  -0.012105 -0.730971  \n",
       "3  1.509226    -0.397162   -0.012105 -0.515485  -0.012105 -0.730971  \n",
       "4  1.509226    -0.397162   -0.012105 -0.515485  -0.012105 -0.730971  \n",
       "\n",
       "[5 rows x 1683 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize X2 using X2.mean() and X2.std()  NOTE: The output is provided for your reference\n",
    "# needs 1 line of code only\n",
    "X2 = (X2 - X2.mean())/X2.std()\n",
    "print(X2.shape)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5460, 1683)\n",
      "(5460,)\n",
      "(1365, 1683)\n",
      "(1365,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to train and test with ratio of 80/20 for train/test respectively\n",
    "# NOTE: Make sure to split X2 and y2, NOT X and y!\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.20)\n",
    "print(X2_train.shape)\n",
    "print(y2_train.shape)\n",
    "print(X2_test.shape)\n",
    "print(y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building NN for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a sequential NN model `nn_reg` with proper configurations for the regression task.\n",
    "\n",
    "> **Hints**:\n",
    "> - `input_dim` of the first layer should match with the number of features in `X2`\n",
    "\n",
    "> - ReLU is usually a good activation function for the hidden layers, but you may also try other activation functions and/or initialization strategies.\n",
    "\n",
    "> - Note that the activation function and number of neurons in the output layer are determined by the type of ML task i.e. Regression.\n",
    "\n",
    "> - The common loss functions for regression are `mae` and `mse` and the metric is usually the same as loss for regression. To keep the results consistent with the requirements, you should use `mae` as the loss function, and the metric would also be `mae`.\n",
    "\n",
    "> - You're going to use callback and early stopping to determine the optimal number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='red'>**Test MAE Loss Requirement**</font>: Your `nn_reg` model's `mae` loss on `X2_test` should not exceed **0.20**, i.e. the test `mae` loss should be 0.20 or lower. Otherwise, your `nn_reg` will get zero points for this part, so you must fine-tune your `nn_reg` and `compile` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build nn_reg with appropriate layers for regression\n",
    "\n",
    "    Hint1: input_dim of the first layer should match with the number of features in X2\n",
    "    \n",
    "    Hint2: The activation function and number of neurons in the output layer are determined\n",
    "    by the type of ML task i.e. Regression\n",
    "    \n",
    "    Hint3: If you observed overfitting in the history plot,\n",
    "    consider using regularization techniques such as Dropout, and/or Batch Normalization '''\n",
    "    #tf.keras.layers.Dropout(0.1),\n",
    "\n",
    "nn_reg = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\", input_dim=1683),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(1, activation=\"relu\")\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer of your choice and set its learning_rate (you may need to tune it)\n",
    "my_learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=my_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, you're going to create `callbacks` and `EarlyStopping`.\n",
    "\n",
    "> **Note:** The `patience` parameter is the number of epochs to monitor for improvement in `EarlyStopping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a callback with EarlyStopping and,\n",
    "    monitor='val_loss',  patience=10 and restore_best_weights=True '''\n",
    "early_stopping_reg = tf.keras.callbacks.EarlyStopping( monitor='val_loss',  \n",
    "                                                      patience=10,\n",
    "                                                      restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Compile nn_reg with loss='mae', optimizer=optimizer and metrics=['mae'] '''\n",
    "nn_reg.compile(optimizer=optimizer,\n",
    "                       loss='mae',\n",
    "                       metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now run the training, sit back and let tf/keras determine the optimal number of epochs! Although the `EPOCHS` is set to 200, the training would usually stop sooner with `EarlyStopping`. You may change/increase `EPOCHS` and/or any other `compile` or `nn_reg` hyperparameter that is necessary to achieve the required test `mae` loss, i.e. 0.2 and less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5590 - mae: 0.5590 - val_loss: 0.3658 - val_mae: 0.3658\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3780 - mae: 0.3780 - val_loss: 0.3558 - val_mae: 0.3558\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3704 - mae: 0.3704 - val_loss: 0.3369 - val_mae: 0.3369\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3637 - mae: 0.3637 - val_loss: 0.3292 - val_mae: 0.3292\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3636 - mae: 0.3636 - val_loss: 0.3358 - val_mae: 0.3358\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3460 - mae: 0.3460 - val_loss: 0.3026 - val_mae: 0.3026\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3198 - mae: 0.3198 - val_loss: 0.2915 - val_mae: 0.2915\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3032 - mae: 0.3032 - val_loss: 0.2990 - val_mae: 0.2990\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3174 - mae: 0.3174 - val_loss: 0.3001 - val_mae: 0.3001\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2821 - mae: 0.2821 - val_loss: 0.2675 - val_mae: 0.2675\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2723 - mae: 0.2723 - val_loss: 0.2812 - val_mae: 0.2812\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2849 - mae: 0.2849 - val_loss: 0.2562 - val_mae: 0.2562\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2724 - mae: 0.2724 - val_loss: 0.2643 - val_mae: 0.2643\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2658 - mae: 0.2658 - val_loss: 0.2538 - val_mae: 0.2538\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2673 - mae: 0.2673 - val_loss: 0.2708 - val_mae: 0.2708\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2420 - mae: 0.2420 - val_loss: 0.2618 - val_mae: 0.2618\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2351 - mae: 0.2351 - val_loss: 0.2353 - val_mae: 0.2353\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2556 - mae: 0.2556 - val_loss: 0.2470 - val_mae: 0.2470\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2378 - mae: 0.2378 - val_loss: 0.2434 - val_mae: 0.2434\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2236 - mae: 0.2236 - val_loss: 0.2398 - val_mae: 0.2398\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2272 - mae: 0.2272 - val_loss: 0.2596 - val_mae: 0.2596\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2279 - mae: 0.2279 - val_loss: 0.2316 - val_mae: 0.2316\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2113 - mae: 0.2113 - val_loss: 0.2327 - val_mae: 0.2327\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2150 - mae: 0.2150 - val_loss: 0.2235 - val_mae: 0.2235\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1950 - mae: 0.1950 - val_loss: 0.2368 - val_mae: 0.2368\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2091 - mae: 0.2091 - val_loss: 0.2385 - val_mae: 0.2385\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1955 - mae: 0.1955 - val_loss: 0.2311 - val_mae: 0.2311\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2001 - mae: 0.2001 - val_loss: 0.2286 - val_mae: 0.2286\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1914 - mae: 0.1914 - val_loss: 0.2147 - val_mae: 0.2147\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1981 - mae: 0.1981 - val_loss: 0.2163 - val_mae: 0.2163\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1934 - mae: 0.1934 - val_loss: 0.2152 - val_mae: 0.2152\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1939 - mae: 0.1939 - val_loss: 0.2101 - val_mae: 0.2101\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1972 - mae: 0.1972 - val_loss: 0.2196 - val_mae: 0.2196\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2239 - mae: 0.2239 - val_loss: 0.2103 - val_mae: 0.2103\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1749 - mae: 0.1749 - val_loss: 0.2147 - val_mae: 0.2147\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1988 - mae: 0.1988 - val_loss: 0.2096 - val_mae: 0.2096\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1906 - mae: 0.1906 - val_loss: 0.2097 - val_mae: 0.2097\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1800 - mae: 0.1800 - val_loss: 0.2149 - val_mae: 0.2149\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1824 - mae: 0.1824 - val_loss: 0.2103 - val_mae: 0.2103\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.1808 - mae: 0.1808 - val_loss: 0.2159 - val_mae: 0.2159\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1809 - mae: 0.1809 - val_loss: 0.2170 - val_mae: 0.2170\n",
      "Epoch 42/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.1892 - mae: 0.1892 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 43/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.2247 - val_mae: 0.2247\n",
      "Epoch 44/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1752 - mae: 0.1752 - val_loss: 0.2201 - val_mae: 0.2201\n",
      "Epoch 45/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.1754 - mae: 0.1754 - val_loss: 0.2298 - val_mae: 0.2298\n",
      "Epoch 46/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.1783 - mae: 0.1783 - val_loss: 0.2457 - val_mae: 0.2457\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "''' Fit nn_reg on X2_train, y2_train, and with epochs=EPOCHS, callbacks=[early_stopping_reg], and\n",
    "    validation_split=0.1 '''\n",
    "\n",
    "nn_reg_history = nn_reg.fit(X2_train, \n",
    "                            y2_train, \n",
    "                            epochs=EPOCHS, \n",
    "                            callbacks=[early_stopping_reg], \n",
    "                            validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' plot the history with a figsize of (10,5)\n",
    "    the plot style should be reset back to 'default'\n",
    "    the plot should display the grid and the whole range of values for loss and mae '''\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.style.use(\"default\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(nn_reg_history.history['loss'], label='loss')\n",
    "plt.plot(nn_reg_history.history['mae'], label='mae')\n",
    "plt.plot(nn_reg_history.history['val_loss'], label='val_los')\n",
    "plt.plot(nn_reg_history.history['val_mae'], label='val_mae')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 934us/step - loss: 0.2015 - mae: 0.2015\n"
     ]
    }
   ],
   "source": [
    "# Evaluate nn_reg on X2_test, y2_test\n",
    "reg_loss, reg_mae = nn_reg.evaluate(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Maximum reg_loss: 0.20 \n",
    "    if reg_loss is higher than 0.2, you should rebuild your nn_reg with new hyperparameters and retrain it '''\n",
    "round(reg_loss, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips To Overcome Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the provided `nn_reg_history` plot, it seems there is no overfitting because `mae` and `val_mae` are decreasing hand-in-hand. That's because regularization techniques have been used in building `nn_reg`, so you should probably use those techniques too, although the beauty of the NNs is that they are so flexible and there might be multiple solutions/architectures that work for a given problem.\n",
    "\n",
    "The following plot shows the history of training the same arhcitecture used for `nn_reg` but without regularization techniques. As the plot displays, there is a large gap between `mae` and `val_mae` (like a crocodile opening its mouth to hunt you!!) which clearly indicates **overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Do NOT write anything here!\n",
    "     This is just to display the overfitting plot '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NNs are so prone to overfitting because they have lots of trainable parameters and hence a large degree of freedom which makes them have a high variance.\n",
    "\n",
    "> As discussed in the lectures, there are various regularization techniques to tackle overfitting in NNs and DNNs. You've already used one regularization technique so far in training `nn_reg` and that was `EarlyStopping`. However, if you notice in your history plot that your model has run into overfitting, consider using other techniques, such as `l2`, `Dropout` and `BatchNormalization`. Recall that although `BatchNormalization` was intended to help with unstable gradients problem, it has regularization effects too.\n",
    "\n",
    "> If you want to use both `Dropout` and `BatchNormalization`, it's easier to use them in the order as in the following cell, i.e. first the dense layer with activation function followed by batch norm followed by dropout, although as discussed in the lectures, BN can be applied before the activation function too. You should certainly fine-tune the probability of `Dropout` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ''' Do NOT write anything here!\n",
    "     This is just to display the BN and dropout '''\n",
    "    ...\n",
    "    tf.keras.layers.Dense(10, activation = \"relu\"), # this is just an example, your dense layers might differ\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2), # dropout probability = 0.2 which may be tuned\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-II - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER THE FOLLOWING QUESTIONS HERE:\n",
    "\n",
    "**Q3 [5 points]** <br>\n",
    "(**a - 3 points**) - Using eraly stopping and callbacks, how may epochs did the training run for `nn_reg`? Find the attribute in `nn_reg_history` object that logs the number of epochs. Write the code to get number of epochs in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]\n"
     ]
    }
   ],
   "source": [
    "''' Get the number of epochs from nn_reg_history object\n",
    "    Hint: it would return a list like below; for you it might be a different number,\n",
    "    dependeing on when EarlyStopping stopped training '''\n",
    "#print(nn_reg_history.history['loss'])\n",
    "\n",
    "epoch_list =[]\n",
    "epoch_list.append(0)\n",
    "i = 0\n",
    "for value in nn_reg_history.history['loss']:\n",
    "    i+=1\n",
    "    epoch_list.append(i)\n",
    "    \n",
    "print(epoch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**b - 2 points**) - How did the training of `nn_reg` stop? Your answer should exactly mention the criteria for when the training stops given the specifications. EXPLAIN CLEARLY AND COMPLETELY IN NO MORE THAN TWO SENTENCES!\n",
    "\n",
    "    A3.b: Training stops when val_loss fails to improve after 10 epochs. That is, the best val_loss is remembered, and if the next 10 epochs fail to improve on the best val_loss remembered, training stops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4 [5 points]** - On the history plot of `nn_reg`, you have four colors displayed in the legend, but you can see only two of them (only the orange and red curves are displayed). Explain why?\n",
    "\n",
    "    A4 There are only two colors visible becasue mae overlaps loss and val_mae overlaps val_loss. Mae and loss are the same measurement in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Assignment-4 has a maximum of 100 points. Make sure that you get the correct outputs/plots for all cells that you implement and give complete answers to all questions. Also, your notebook should be written with no grammatical and spelling errors and should be easy-to-read.\n",
    "\n",
    "The breakdown of the 100 points is as follows:\n",
    "\n",
    "- Part-I Multi-Class Classification: [total 50 points]\n",
    "    - Implementation of `baseline_model`: 10 points - **val_accuracy Requirement**: 0.85 after the last epoch otherwise zero points\n",
    "    - Implementation of `nn_clf`: 10 points - **Test Accuracy Requirement**: accuracy on `X_test` should be 0.99 otherwise zero points\n",
    "    - Accuracy vs Learning Rate plot: 20 points - Incomplete/wrong plots get zero points\n",
    "    - Questions: 10 points (5 points each)\n",
    "\n",
    "\n",
    "- Part-II Regression on `NA_Sales`: [total 50 points]\n",
    "    - Implementation of nn_reg: 40 points - **Test MAE Loss Requirement**: 0.20 for `mae` loss on `X2_test` otherwise zero points \n",
    "    - Questions: 10 points (5 points each)\n",
    "   \n",
    "\n",
    "<b>Note: </b>Follow the instructions of each section carefully. Up to 10 points may be deducted if your submitted notebook is not easy to read and follow or if it has grammatical, spelling or formatting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-A4.ipynb```. Submit the completed notebook using the ```Assignment-4``` link on Blackboard.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct implementation and results\n",
    "  * correct answer to the questions\n",
    "  * complete running of all required cells\n",
    "  * readability of the notebook\n",
    "  \n",
    "<font color=red><b>Due Date: Tuesday May 4th, 11:59PM.</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
